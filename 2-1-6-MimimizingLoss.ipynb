{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gtmQDB6EjReV"
      },
      "outputs": [],
      "source": [
        "# First import the functions we will need\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7OQWzQOW_idB"
      },
      "outputs": [],
      "source": [
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))\n",
        "\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5-58WYokl3"
      },
      "source": [
        "# GradientTape\n",
        "\n",
        "The Calculus is managed by a TensorFlow Gradient Tape. You can learn more about the gradient tape at https://www.tensorflow.org/api_docs/python/tf/GradientTape, and we will discuss it later in the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JdhgbGE2j02L"
      },
      "outputs": [],
      "source": [
        "# Define our initial guess\n",
        "INITIAL_W = 10.0\n",
        "INITIAL_B = 10.0\n",
        "\n",
        "# Define our loss function\n",
        "def loss(predicted_y, target_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - target_y))\n",
        "\n",
        "# Define our training procedure\n",
        "def train(model, inputs, outputs, learning_rate):\n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(model(inputs), outputs)\n",
        "    # Here is where you differentiate the model values with respect to the loss function\n",
        "    dw, db = t.gradient(current_loss, [model.w, model.b])\n",
        "    # And here is where you update the model values based on the learning rate chosen\n",
        "    model.w.assign_sub(learning_rate * dw)\n",
        "    model.b.assign_sub(learning_rate * db)\n",
        "    return current_loss\n",
        "\n",
        "# Define our simple linear regression model\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    # Initialize the weights\n",
        "    self.w = tf.Variable(INITIAL_W)\n",
        "    self.b = tf.Variable(INITIAL_B)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.w * x + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d-Eloga_idI"
      },
      "source": [
        "### Train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8akmDCoAjgak",
        "outputId": "2507caa1-66a6-4b92-97d1-1bd38759ef42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0: w=10.00 b=10.00, loss=715.66669\n",
            "Epoch  1: w=-0.41 b=5.86, loss=27.47032\n",
            "Epoch  2: w=-0.02 b=5.28, loss=22.43888\n",
            "Epoch  3: w=0.16 b=4.69, loss=18.46284\n",
            "Epoch  4: w=0.33 b=4.16, loss=15.19137\n",
            "Epoch  5: w=0.49 b=3.68, loss=12.49958\n",
            "Epoch  6: w=0.63 b=3.25, loss=10.28476\n",
            "Epoch  7: w=0.76 b=2.85, loss=8.46238\n",
            "Epoch  8: w=0.87 b=2.50, loss=6.96291\n",
            "Epoch  9: w=0.98 b=2.17, loss=5.72914\n",
            "Epoch 10: w=1.07 b=1.88, loss=4.71398\n",
            "Epoch 11: w=1.16 b=1.61, loss=3.87870\n",
            "Epoch 12: w=1.24 b=1.37, loss=3.19143\n",
            "Epoch 13: w=1.31 b=1.15, loss=2.62593\n",
            "Epoch 14: w=1.37 b=0.95, loss=2.16064\n",
            "Epoch 15: w=1.43 b=0.77, loss=1.77779\n",
            "Epoch 16: w=1.48 b=0.60, loss=1.46278\n",
            "Epoch 17: w=1.53 b=0.45, loss=1.20359\n",
            "Epoch 18: w=1.57 b=0.32, loss=0.99032\n",
            "Epoch 19: w=1.61 b=0.20, loss=0.81484\n",
            "Epoch 20: w=1.65 b=0.08, loss=0.67046\n",
            "Epoch 21: w=1.68 b=-0.02, loss=0.55166\n",
            "Epoch 22: w=1.71 b=-0.11, loss=0.45391\n",
            "Epoch 23: w=1.74 b=-0.19, loss=0.37348\n",
            "Epoch 24: w=1.76 b=-0.27, loss=0.30730\n",
            "Epoch 25: w=1.79 b=-0.33, loss=0.25285\n",
            "Epoch 26: w=1.81 b=-0.40, loss=0.20805\n",
            "Epoch 27: w=1.82 b=-0.45, loss=0.17118\n",
            "Epoch 28: w=1.84 b=-0.50, loss=0.14085\n",
            "Epoch 29: w=1.85 b=-0.55, loss=0.11589\n",
            "Epoch 30: w=1.87 b=-0.59, loss=0.09536\n",
            "Epoch 31: w=1.88 b=-0.63, loss=0.07846\n",
            "Epoch 32: w=1.89 b=-0.66, loss=0.06456\n",
            "Epoch 33: w=1.90 b=-0.69, loss=0.05312\n",
            "Epoch 34: w=1.91 b=-0.72, loss=0.04371\n",
            "Epoch 35: w=1.92 b=-0.75, loss=0.03596\n",
            "Epoch 36: w=1.93 b=-0.77, loss=0.02959\n",
            "Epoch 37: w=1.93 b=-0.79, loss=0.02435\n",
            "Epoch 38: w=1.94 b=-0.81, loss=0.02003\n",
            "Epoch 39: w=1.95 b=-0.83, loss=0.01648\n",
            "Epoch 40: w=1.95 b=-0.85, loss=0.01356\n",
            "Epoch 41: w=1.95 b=-0.86, loss=0.01116\n",
            "Epoch 42: w=1.96 b=-0.87, loss=0.00918\n",
            "Epoch 43: w=1.96 b=-0.88, loss=0.00756\n",
            "Epoch 44: w=1.97 b=-0.90, loss=0.00622\n",
            "Epoch 45: w=1.97 b=-0.91, loss=0.00511\n",
            "Epoch 46: w=1.97 b=-0.91, loss=0.00421\n",
            "Epoch 47: w=1.97 b=-0.92, loss=0.00346\n",
            "Epoch 48: w=1.98 b=-0.93, loss=0.00285\n",
            "Epoch 49: w=1.98 b=-0.94, loss=0.00234\n"
          ]
        }
      ],
      "source": [
        "# Define our input data and learning rate\n",
        "xs = [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
        "ys = [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]\n",
        "LEARNING_RATE=0.09\n",
        "\n",
        "# Instantiate our model\n",
        "model = Model()\n",
        "\n",
        "# Collect the history of w-values and b-values to plot later\n",
        "list_w, list_b = [], []\n",
        "epochs = range(50)\n",
        "losses = []\n",
        "for epoch in epochs:\n",
        "  list_w.append(model.w.numpy())\n",
        "  list_b.append(model.b.numpy())\n",
        "  current_loss = train(model, xs, ys, learning_rate=LEARNING_RATE)\n",
        "  losses.append(current_loss)\n",
        "  print(f\"Epoch {epoch:2d}: w={list_w[-1]:1.2f} b={list_b[-1]:1.2f}, \"\n",
        "        f\"loss={current_loss:2.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQzQDkXW_idK"
      },
      "source": [
        "### Plot our trained values over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGgb5grSk8Ax"
      },
      "outputs": [],
      "source": [
        "# Plot the w-values and b-values for each training Epoch against the true values\n",
        "TRUE_w = 2.0\n",
        "TRUE_b = -1.0\n",
        "plt.plot(epochs, list_w, 'r', epochs, list_b, 'b')\n",
        "plt.plot([TRUE_w] * len(epochs), 'r--', [TRUE_b] * len(epochs), 'b--')\n",
        "plt.legend(['w', 'b', 'True w', 'True b'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Mimimizing-Loss.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}