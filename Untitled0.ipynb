{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZrUgEWE28cYy4ovHCdSyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishiNiranjan/Examples/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "737d7d56"
      },
      "source": [
        "### 1. Generate Synthetic Data\n",
        "\n",
        "Let's create some simple linear data with a bit of noise to train our model on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29b89a73"
      },
      "source": [
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_label), (val_images, val_labels) = mnist.load_data()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images / 255.0\n",
        "val_images = val_images / 255.0\n",
        "print(training_images[20][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlZ1iwQFhUQd",
        "outputId": "bee09971-bde3-4097-f1c4-a1bc6cda5095"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.00392157\n",
            " 0.         0.         0.         0.25490196 0.38823529 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.41568627 0.23529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [ tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "      tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "     ])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_label, epochs=20, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JnaXgGrQijoj",
        "outputId": "2456c2f3-80d3-4ab5-a3a1-c6f8ee0f71c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.7692 - val_accuracy: 0.8401 - val_loss: 0.4662\n",
            "Epoch 2/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.4348 - val_accuracy: 0.8427 - val_loss: 0.4445\n",
            "Epoch 3/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.4035 - val_accuracy: 0.8494 - val_loss: 0.4346\n",
            "Epoch 4/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3823 - val_accuracy: 0.8402 - val_loss: 0.4616\n",
            "Epoch 5/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3685 - val_accuracy: 0.8513 - val_loss: 0.4196\n",
            "Epoch 6/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3681 - val_accuracy: 0.8574 - val_loss: 0.4127\n",
            "Epoch 7/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.3456 - val_accuracy: 0.8542 - val_loss: 0.4173\n",
            "Epoch 8/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3465 - val_accuracy: 0.8605 - val_loss: 0.3960\n",
            "Epoch 9/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3386 - val_accuracy: 0.8605 - val_loss: 0.3978\n",
            "Epoch 10/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.3336 - val_accuracy: 0.8620 - val_loss: 0.3893\n",
            "Epoch 11/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3246 - val_accuracy: 0.8527 - val_loss: 0.4166\n",
            "Epoch 12/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3228 - val_accuracy: 0.8619 - val_loss: 0.3937\n",
            "Epoch 13/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3118 - val_accuracy: 0.8640 - val_loss: 0.3852\n",
            "Epoch 14/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.3132 - val_accuracy: 0.8619 - val_loss: 0.3883\n",
            "Epoch 15/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3101 - val_accuracy: 0.8577 - val_loss: 0.4022\n",
            "Epoch 16/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.3023 - val_accuracy: 0.8468 - val_loss: 0.4218\n",
            "Epoch 17/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3013 - val_accuracy: 0.8635 - val_loss: 0.3852\n",
            "Epoch 18/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.2973 - val_accuracy: 0.8616 - val_loss: 0.3993\n",
            "Epoch 19/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2937 - val_accuracy: 0.8591 - val_loss: 0.4084\n",
            "Epoch 20/20\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2934 - val_accuracy: 0.8650 - val_loss: 0.3895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dbd720ac4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first output line come from here. This runs evaluation through 313 batches (because your validation set size / batch size = 313). and gives accuracy percentage\n",
        "model.evaluate(val_images, val_labels)\n",
        "# seconf line of outut came from here\n",
        "classifications = model.predict(val_images)\n",
        "#If your model has 10 classes, Each number = “probability the image is this class.” I have 10 final classification neuron in output layer\n",
        "print(classifications[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eULA3aTZl0aR",
        "outputId": "dd716ec0-88fa-4245-cd76-5d17a4fefd3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.3797\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "[1.7913046e-05 7.6929522e-12 1.1812451e-05 1.2040991e-06 7.3967283e-07\n",
            " 3.1181320e-03 2.0035992e-04 8.2190059e-02 8.3263449e-06 9.1445148e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as layer 1 has 20 neurons and input_size is 28*28=784\n",
        "# You are imagining one weight per neuron.\n",
        "# That is NOT how Dense layers work.\n",
        "# A neuron does NOT have “one weight.”\n",
        "# A neuron has one weight PER INPUT FEATURE.\n",
        "# Your input has 784 features (28×28 pixels flattened).\n",
        "# Therefore:\n",
        "# Each neuron must have 784 weights.\n",
        "# That’s 785 parameters per neuron (784 weights + 1 bias)\n",
        "# so total parameter count for this layer is weights(784 weights × 20 neurons = 15,680) + bias(1 bias per neuron = 20)\n",
        "# 15,680 + 20 = 15,700\n",
        "#The Dense layer has a total of 15,700 trainable parameters.\n",
        "\n",
        "# layer2 will conatin total weights 200\n",
        "# return 200.\n",
        "\n",
        "# There are 10 neurons in this layer, but there are 20 neurons in the previous layer.\n",
        "# So, each neuron in this layer will learn a weight for the incoming value from the previous layer"
      ],
      "metadata": {
        "id": "3QUedm2XqgCL"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}